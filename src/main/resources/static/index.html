<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>üé§ Interview Bot - Real-time Streaming</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 50px auto;
            padding: 20px;
            background-color: #f5f5f5;
        }
        .container {
            background: white;
            padding: 30px;
            border-radius: 10px;
            box-shadow: 0 2px 10px rgba(0, 0, 0, 0.1);
        }
        h1 {
            text-align: center;
            color: #333;
        }
        .status {
            padding: 10px;
            margin: 10px 0;
            border-radius: 5px;
            font-weight: bold;
        }
        .connected {
            background-color: #d4edda;
            color: #155724;
        }
        .disconnected {
            background-color: #f8d7da;
            color: #721c24;
        }
        .controls {
            text-align: center;
            margin: 20px 0;
        }
        button {
            padding: 10px 20px;
            margin: 5px;
            font-size: 16px;
            border: none;
            border-radius: 5px;
            background-color: #007bff;
            color: white;
            cursor: pointer;
        }
        button:hover {
            background-color: #0056b3;
        }
        button:disabled {
            background-color: #ccc;
            cursor: not-allowed;
        }
        .recording {
            background-color: #dc3545 !important;
            animation: pulse 1.5s infinite;
        }
        @keyframes pulse {
            0%, 100% { opacity: 1; }
            50% { opacity: 0.7; }
        }
        input {
            width: 70%;
            padding: 10px;
            border: 1px solid #ddd;
            border-radius: 5px;
            font-size: 14px;
        }
        #messages {
            background-color: #f8f9fa;
            border: 1px solid #ddd;
            border-radius: 5px;
            padding: 15px;
            height: 300px;
            overflow-y: auto;
            margin-top: 20px;
            white-space: pre-wrap;
        }
        .message {
            padding: 5px 0;
            border-bottom: 1px solid #eee;
        }
        .sent {
            color: #007bff;
        }
        .received {
            color: #28a745;
        }
        .bot {
            color: #ff4081;
            font-weight: bold;
        }
    </style>
</head>
<body>
<div class="container">
    <h1>üéô Interview Bot - Real-time Streaming</h1>

    <div id="status" class="status disconnected">‚ùå Disconnected</div>

    <div class="controls">
        <button id="connectBtn" onclick="connect()">Connect</button>
        <button id="disconnectBtn" onclick="disconnect()" disabled>
            Disconnect
        </button>
    </div>

    <div class="controls">
        <input
                type="text"
                id="messageInput"
                placeholder="Type a message..."
                disabled
        />
        <button id="sendBtn" onclick="sendMessage()" disabled>Send</button>
    </div>

    <div class="controls">
        <button id="micBtn" onclick="toggleMic()" disabled>
            üé§ Start Mic
        </button>
    </div>

    <div id="messages"><p><em>No messages yet...</em></p></div>
</div>

<script>
    let ws, audioContext, micStream, processor, source;
    let isRecording = false;
    let audioQueue = [];
    let isPlaying = false;

    const statusDiv = document.getElementById("status");
    const messageInput = document.getElementById("messageInput");
    const messagesDiv = document.getElementById("messages");
    const connectBtn = document.getElementById("connectBtn");
    const disconnectBtn = document.getElementById("disconnectBtn");
    const sendBtn = document.getElementById("sendBtn");
    const micBtn = document.getElementById("micBtn");

    let chunkBuffer = [];

    async function connect() {
        try {
            // Initialize audio context on user interaction (required for Mac/Safari)
            if (!audioContext) {
                audioContext = new (window.AudioContext || window.webkitAudioContext)({
                    sampleRate: 48000 // Higher sample rate for better quality
                });
                await audioContext.resume();
            }

            const wsUrl = `ws://${window.location.host}/interview`;
            ws = new WebSocket(wsUrl);
            ws.binaryType = "arraybuffer";

            ws.onopen = () => {
                updateStatus(true);
                connectBtn.disabled = true;
                disconnectBtn.disabled = false;
                messageInput.disabled = false;
                sendBtn.disabled = false;
                micBtn.disabled = false;
                addMessage("System", "Connected and ready!", "received");
            };

            ws.onmessage = async (event) => {
                if (event.data instanceof ArrayBuffer) {
                    chunkBuffer.push(new Uint8Array(event.data));
                    return;
                }

                const msg = safeParse(event.data);
                if (msg?.type === "tts_end") {
                    await playBufferedAudio();
                } else {
                    handleText(msg);
                }
            };

            ws.onclose = () => {
                updateStatus(false);
                connectBtn.disabled = false;
                disconnectBtn.disabled = true;
                messageInput.disabled = true;
                sendBtn.disabled = true;
                micBtn.disabled = true;
                stopMicStream();
            };

            ws.onerror = (error) => {
                console.error("WebSocket error:", error);
                addMessage("System", "Connection error", "received");
            };
        } catch (error) {
            console.error("Connection error:", error);
            addMessage("System", "Failed to connect: " + error.message, "received");
        }
    }

    function disconnect() {
        if (ws) {
            ws.close();
        }
        stopMicStream();
    }

    function safeParse(d) {
        try {
            return JSON.parse(d);
        } catch {
            return null;
        }
    }

    async function playBufferedAudio() {
        if (!chunkBuffer.length) {
            console.warn("No audio chunks to play");
            return;
        }

        // Merge all chunks
        const total = chunkBuffer.reduce((a, b) => a + b.length, 0);
        const merged = new Uint8Array(total);
        let offset = 0;
        chunkBuffer.forEach(chunk => {
            merged.set(chunk, offset);
            offset += chunk.length;
        });
        chunkBuffer = [];

        try {
            // Create blob and play
            const blob = new Blob([merged], { type: 'audio/mpeg' });
            const url = URL.createObjectURL(blob);

            addMessage("System", "üîä Playing response...", "received");

            // Create new audio element for each response
            const audio = new Audio();
            audio.src = url;

            // Wait for audio to be ready
            await new Promise((resolve, reject) => {
                audio.oncanplaythrough = resolve;
                audio.onerror = reject;
                audio.load();
            });

            // Play audio
            await audio.play();

            // Wait for playback to finish
            await new Promise(resolve => {
                audio.onended = resolve;
            });

            // Cleanup
            URL.revokeObjectURL(url);

        } catch (e) {
            console.error("Audio playback error:", e);
            addMessage("System", "Error playing audio: " + e.message, "received");
        }
    }

    function handleText(msg) {
        if (msg?.type === "Results" && msg.channel?.alternatives?.length) {
            const t = msg.channel.alternatives[0].transcript;
            if (t && t.trim()) addMessage("You (STT)", t, "sent");
        } else if (msg?.type === "bot_text") {
            addMessage("Bot", msg.data, "bot");
        }
    }

    function sendMessage() {
        const text = messageInput.value.trim();
        if (text && ws?.readyState === WebSocket.OPEN) {
            ws.send(text);
            addMessage("You", text, "sent");
            messageInput.value = "";
        }
    }

    function addMessage(sender, text, type) {
        const div = document.createElement("div");
        div.className = `message ${type}`;
        div.textContent = `[${sender}] ${text}`;
        messagesDiv.appendChild(div);
        messagesDiv.scrollTop = messagesDiv.scrollHeight;
    }

    function updateStatus(connected) {
        statusDiv.textContent = connected ? "‚úÖ Connected" : "‚ùå Disconnected";
        statusDiv.className = connected ? "status connected" : "status disconnected";
    }

    async function toggleMic() {
        if (isRecording) {
            stopMicStream();
        } else {
            await startMicStream();
        }
    }

    async function startMicStream() {
        if (!ws || ws.readyState !== WebSocket.OPEN) {
            alert("Connect WebSocket first!");
            return;
        }
        try {
            micStream = await navigator.mediaDevices.getUserMedia({
                audio: {
                    channelCount: 1,
                    sampleRate: 16000,
                    echoCancellation: true,
                    noiseSuppression: true,
                    autoGainControl: true
                }
            });

            const micCtx = new AudioContext({ sampleRate: 16000 });
            source = micCtx.createMediaStreamSource(micStream);
            processor = micCtx.createScriptProcessor(4096, 1, 1);
            source.connect(processor);
            processor.connect(micCtx.destination);

            processor.onaudioprocess = (e) => {
                const input = e.inputBuffer.getChannelData(0);
                const buffer = new ArrayBuffer(input.length * 2);
                const view = new DataView(buffer);
                for (let i = 0; i < input.length; i++) {
                    let s = Math.max(-1, Math.min(1, input[i]));
                    view.setInt16(i * 2, s < 0 ? s * 0x8000 : s * 0x7fff, true);
                }
                if (ws.readyState === WebSocket.OPEN) ws.send(buffer);
            };

            isRecording = true;
            micBtn.textContent = "üõë Stop Mic";
            micBtn.classList.add("recording");
            addMessage("System", "üé§ Mic streaming started...", "received");
        } catch (err) {
            console.error("Mic error:", err);
            addMessage("System", "Mic access failed: " + err.message, "received");
        }
    }

    function stopMicStream() {
        if (processor) processor.disconnect();
        if (source) source.disconnect();
        if (micStream) micStream.getTracks().forEach(t => t.stop());
        isRecording = false;
        micBtn.textContent = "üé§ Start Mic";
        micBtn.classList.remove("recording");
        addMessage("System", "üõë Mic stopped", "received");
    }

    // Allow Enter key to send message
    messageInput.addEventListener("keypress", (e) => {
        if (e.key === "Enter") {
            sendMessage();
        }
    });
</script>

</body>
</html>